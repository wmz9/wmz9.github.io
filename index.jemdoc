# jemdoc: menu{MENU}{index.html}, nofooter
# jemdoc: addcss{jemdoc.css}, notime
==Mingze Wang

~~~
{}{img_left}{mingzewang.jpeg}{Mingze Wang}{171 px}{200 px}
Mingze Wang (王铭泽) \n
Ph.D. Candidate

[https://www.math.pku.edu.cn/ School of Mathematical Sciences] \n
[https://english.pku.edu.cn/ Peking University]

210, Jingyuan Building \#6 (静园六院), Peking University\n
Beijing, China, 100084\n
Email: mingzewang \[at\] stu \[dot\] pku \[dot\] edu \[dot\] cn\n

\[[https://scholar.google.com/citations?user=CkU47X0AAAAJ&hl=zh-CN&oi=ao Google Scholar]\] ~~~ \[[cv.pdf CV]\]\n
~~~

== About me
I am a third-year Ph.D student in Computational Mathematics, [https://www.math.pku.edu.cn/ School of Mathematical Sciences], [https://english.pku.edu.cn/ Peking University] (2021-Present). I am very fortunate to be advised by [https://web.math.princeton.edu/~weinan/ Prof. Weinan E]. Prior to that, I received my B.S. degree in Pure and Applied Mathematics (ranking 1/111 for the first three years during my undergraduate study) from [http://www.math.zju.edu.cn/mathen/ School of Mathematical Sciences], [https://www.zju.edu.cn/ Zhejiang University], Hangzhou, China in 2021.

~~~
Please feel free to drop me an email if you are interested in collaborating with me.
~~~

~~~
== News
- \[2023.09\] One paper accepted to NeurIPS 2023 as a {{<font color=red>}}Spotlight{{</font>}} (Top 3%)!
- \[2022.11\] I have passed the Ph.D. qualifying exam!
- \[2022.10\] I won the 2021-2022 PKU Academic Innovation Award (Top 1%)!
- \[2022.09\] Two papers accepted to NeurIPS 2022!
~~~


== Research Interests
I am broadly interested in theory, algorithm and application of machine learning. I am also interested in non-convex and convex optimization. Specifically, my recent research topics are
- *Deep Learning Theory*: optimization, generalization, implicit bias and approximation.
- *Foundation Model and Transformer*: theory and algorithm.
- *Non-convex and Convex Optimization*: theory and algorithm.
- *AI for Compositional Optimization*: theory and algorithm.
- *CV and NLP*: algorithm and application.

== Recent Publications
- [https://arxiv.org/abs/2305.12467 *Understanding Multi-phase Optimization Dynamics and Rich Nonlinear Behaviors of ReLU Networks*] \n
*Mingze Wang*, Chao Ma\n
+Thirty-seventh Conference on Neural Information Processing Systems+ (*NeurIPS 2023*) ({{<font color=red size=+0.5><b>}}Spotlight, Top 3%{{</b></font>}}).
- [https://arxiv.org/abs/2206.02139 *Early Stage Convergence and Global Convergence of Training Mildly Parameterized Neural Networks*] \n
*Mingze Wang*, Chao Ma\n
+Thirty-sixth Conference on Neural Information Processing Systems+ (*NeurIPS 2022*).
- [https://arxiv.org/abs/2207.02628 *The alignment property of SGD noise and how it helps select flat minima: A stability analysis*] \n
Lei Wu, *Mingze Wang*, Weijie J. Su\n
+Thirty-sixth Conference on Neural Information Processing Systems+ (*NeurIPS 2022*).

== Recent Preprints
- *Achieving Margin Maximization Exponentially Fast via Progressive Norm Rescaling* \n
*Mingze Wang*, Zeping Min, Lei Wu\n
under review, Sep 2023.
- *The Noise Geometry of Stochastic Gradient Descent: A Quantitative and Analytical Characterization* \n
*Mingze Wang*, Lei Wu\n
under review, Sep 2023.
- [https://arxiv.org/abs/2206.03299 *Generalization Error Bounds for Deep Neural Networks Trained by SGD*] \n
*Mingze Wang*, Chao Ma\n
arXiv preprint, June 2022.


== 
